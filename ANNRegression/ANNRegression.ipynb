{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5b7f3d-85f3-4262-999c-02410d3198e7",
   "metadata": {},
   "source": [
    "# Regression using an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5416b-fb3a-47a5-82ce-44c7054627d3",
   "metadata": {},
   "source": [
    "A simple ANN regression model built using the ['Combined Cycle Power Plant'](https://archive.ics.uci.edu/dataset/294/combined+cycle+power+plant) dataset from the UC Irvine Machine Learning Repository, and as part of a [Udemy course](https://www.udemy.com/course/linear-regression-with-artificial-neural-network/learn/lecture/18888982#overview) on building a regression model with an ANN. The dataset consists of 9568 data points collected from a Combined Cycle Power Plant. Features are as follows.\n",
    "- Temperature (T) in the range 1.81°C and 37.11°C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (EP) 420.26-495.76 MW\n",
    "\n",
    "This model attempts to predict hourly electrical output given the Temperature, Ambient Pressure, Relative Humidity and Exhaust Vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159de21-1113-4131-ae3a-8211a582107c",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "***\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd15f46-f0b1-40b2-9c6f-6b2aa39c938a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a298a-2ab1-4969-ab7c-d24bb60422f2",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "***\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce340c-5587-478f-a0c6-8bf3d8c269a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2880b2a-ca12-4af5-9b45-408f7a170a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('Folds5x2_pp.xlsx')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9eace2a-14f3-4e59-8cbd-a34f19411928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.96   41.76 1024.07   73.17]\n",
      " [  25.18   62.96 1020.04   59.08]\n",
      " [   5.11   39.4  1012.16   92.14]\n",
      " ...\n",
      " [  31.32   74.33 1012.92   36.48]\n",
      " [  24.48   69.45 1013.86   62.39]\n",
      " [  21.6    62.52 1017.23   67.87]]\n",
      "[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e7752-b887-42eb-a458-2bee1b5c5c11",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "### **Split the dataset into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98fab0bb-4bdb-49d1-b833-8c8d6b858894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_size: Sets the size of the test set to 20% of the original dataset\n",
    "# random_state: Sets randomisation of the splitting process to zero, ensuring that the data is always split in the same way\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e72e2e-e7b4-410c-bb60-bf1eae33186a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "***\n",
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5c650a-1640-42d4-be70-ba7ade354ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "# Input and 1st layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Second layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "# Note: No activation function on the output neuron, as the output should be a continuous real number\n",
    "ann.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "# 'adam' : Optimizer used during back propagation. Better than SGD as it adapts the learning rate, and uses momentum to navigate steep/shallow gradients\n",
    "# 'mean_squared_error' : Loss function which penalises predictions that are further away from the actual value more than those that are closer\n",
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15f2f5-b641-49a8-a555-5133462ba9af",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "***\n",
    "## Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dd9056-95b2-44ce-8ebd-afc971937f1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c_vV-tiiA5zn",
    "outputId": "4a2b6ee6-ed75-4698-9069-b250e613803f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 1s 849us/step - loss: 12358.4990\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 824us/step - loss: 195.5432\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 816us/step - loss: 186.9117\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 812us/step - loss: 176.0876\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 806us/step - loss: 163.9512\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 796us/step - loss: 151.3801\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 137.6919\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 124.6469\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 776us/step - loss: 111.5338\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 99.5052\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 786us/step - loss: 88.6133\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 78.7908\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 789us/step - loss: 70.8080\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 63.6030\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 57.7856\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 53.1208\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 49.7769\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 46.8355\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 790us/step - loss: 44.0665\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 790us/step - loss: 42.2736\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 40.6624\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 789us/step - loss: 38.8782\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 37.7340\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 790us/step - loss: 36.5665\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 35.4904\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 34.4797\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 33.5632\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 786us/step - loss: 33.4680\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 793us/step - loss: 32.1576\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 31.3072\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 816us/step - loss: 31.2719\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 804us/step - loss: 30.5686\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 829us/step - loss: 30.3956\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 821us/step - loss: 29.4696\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 794us/step - loss: 28.8670\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 800us/step - loss: 29.0802\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 834us/step - loss: 28.6291\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 896us/step - loss: 27.7640\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 856us/step - loss: 28.4692\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 825us/step - loss: 28.8089\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 27.3333\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 848us/step - loss: 27.7735\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 852us/step - loss: 28.2082\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 835us/step - loss: 27.3133\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 868us/step - loss: 27.3020\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 871us/step - loss: 27.0466\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 877us/step - loss: 27.0257\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 842us/step - loss: 26.5899\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 802us/step - loss: 26.7723\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 789us/step - loss: 27.2052\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 778us/step - loss: 26.8421\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 811us/step - loss: 26.8348\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 789us/step - loss: 26.9411\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 775us/step - loss: 26.8392\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 774us/step - loss: 26.4203\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.3654\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 777us/step - loss: 26.7219\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 779us/step - loss: 27.2737\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 27.4239\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.9836\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 26.6801\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 779us/step - loss: 26.6835\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 786us/step - loss: 26.9873\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 26.7498\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.4530\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 781us/step - loss: 26.3588\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 26.7320\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 779us/step - loss: 26.4810\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 777us/step - loss: 27.0808\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 27.1502\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.9035\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 26.8352\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 821us/step - loss: 26.5092\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 815us/step - loss: 26.8595\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 789us/step - loss: 27.3161\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 800us/step - loss: 26.7512\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 804us/step - loss: 26.8019\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 781us/step - loss: 26.5652\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 781us/step - loss: 27.0762\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 782us/step - loss: 26.9699\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 26.7627\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 26.7943\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 26.9749\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 820us/step - loss: 26.8451\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 787us/step - loss: 27.1392\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 774us/step - loss: 26.4614\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 26.6929\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 799us/step - loss: 26.4591\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 812us/step - loss: 26.8439\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 824us/step - loss: 26.9904\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 791us/step - loss: 27.4082\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 26.7358\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.4014\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.6083\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 786us/step - loss: 26.5715\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 26.9559\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.6780\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s 785us/step - loss: 26.8659\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 788us/step - loss: 27.3707\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 783us/step - loss: 26.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251ce4b2bc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691c3a4-dcd9-418a-87e1-aecb9afd093c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "***\n",
    "## Predictions using the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a2106b-7dc0-4489-acc8-67326eb37888",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "IA0yApEmBG1X",
    "outputId": "cb981e1f-9204-4a2a-fece-9d66a6919189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 679us/step\n",
      "[[430.79 431.23]\n",
      " [461.83 460.01]\n",
      " [465.33 461.14]\n",
      " ...\n",
      " [472.59 473.26]\n",
      " [439.31 438.  ]\n",
      " [458.56 463.28]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555638ea-dba5-409a-aee8-479700bd5b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "***\n",
    "## Determining ANN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7191e054-9edb-4859-b390-da85d603c12a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 24.81889039765765\n",
      "Mean Absolute Error (MAE): 3.940058547192357\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850effa-2caa-40df-802c-aae69cd1846e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
